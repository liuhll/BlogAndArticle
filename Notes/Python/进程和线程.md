# 进程与线程
@(Python)[进程与线程]

## 多任务
- 就是操作系统可以同时运行多个任务
- 单核CPU是怎么执行多任务的呢？
   - 操作系统**轮流让各个任务交替执行**，任务1执行0.01秒，切换到任务2，任务2执行0.01秒，再切换到任务3，执行0.01秒……这样反复执行下去。表面上看，每个任务都是交替执行的，但是，由于CPU的执行速度实在是太快了，我们感觉就像所有任务都在同时执行一样

- 并行执行多任务只能在多核CPU上实现，由于任务数量远远多于CPU的核心数量，所以，操作系统也会自动把很多任务轮流调度到每个核心上执行

- 一个任务就是一个`进程（Process）`
- 在一个**进程内部**，要同时干多件事，就需要同时运行多个`子任务`，我们把进程内的这些“子任务”称为`线程（Thread）`
- 一个进程至少有一个线程
> 多线程的执行方式和多进程是一样的，也是由**操作系统在多个线程之间快速切换**，让每个线程都短暂地交替运行，看起来就像同时执行一样

- 同时执行多个任务怎么办？
  - 多任务的实现有3种方式
  1. 多进程模式
  2. 多线程模式
  3. 多进程+多线程模式

- 多进程和多线程的程序的复杂度要远远高于我们前面写的单进程单线程的程序,原因？
  - 同时执行多个任务通常各个任务之间并**不是没有关联的**，而是**需要相互通信和协调**
- Python既支持多进程，又支持多线程
> - **线程是最小的执行单元**，而**进程由至少一个线程组成**。  
> - 如何调度进程和线程，完全由操作系统决定，**程序自己不能决定什么时候执行，执行多长时间。**

## 多进程----multiprocessing

### 操作系统的相关知识
- Unix/Linux操作系统提供了一个`fork()`系统调用
  - `fork()`调用一次，**返回两次**，因为操作系统自动把`当前进程`（称为父进程）**复制了一份**（称为子进程），
  然后，分别在父进程和子进程内返回
  - 子进程永远返回`0`，而父进程返回子进程的`ID`
  - 一个父进程可以`fork`出很多子进程
  - 父进程要记下每个子进程的ID，而子进程只需要调用`getppid()`就可以拿到父进程的ID
- Python的`os模块`封装了常见的**系统调用**，其中就包括`fork`
- Windows**没有**`fork`调用，上面的代码在Windows上无法运行  

- 有了`fork`调用，一个进程在接到新任务时就可以复制出一个子进程来处理新任务，
> 常见的Apache服务器就是由**父进程监听端口**，每当有新的http请求时，就fork出子进程来处理新的http请求

### multiprocessing
- Python是跨平台的，自然也应该提供一个跨平台的多进程支持
- `multiprocessing模块`就是跨平台版本的多进程模块
- `multiprocessing模块`提供了一个`Process类`来代表一个**进程对象**

```Python
from multiprocessing import Process
import os

# 子进程要执行的代码
def run_proc(name):
    print 'Run child process %s (%s)...' % (name, os.getpid())

if __name__=='__main__':
    print 'Parent process %s.' % os.getpid()
    p = Process(target=run_proc, args=('test',))
    print 'Process will start.'
    p.start()
    p.join()  #join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步
    print 'Process end.'
```

### Pool
- 启动大量的子进程，可以用`进程池`的方式**批量创建子进程**
```python
from multiprocessing import Pool
import os, time, random

def long_time_task(name):
    print 'Run task %s (%s)...' % (name, os.getpid())
    start = time.time()
    time.sleep(random.random() * 3)
    end = time.time()
    print 'Task %s runs %0.2f seconds.' % (name, (end - start))

if __name__=='__main__':
    print 'Parent process %s.' % os.getpid()
    p = Pool()
    for i in range(5):
        p.apply_async(long_time_task, args=(i,))
    print 'Waiting for all subprocesses done...'
    p.close()
    p.join()
    print 'All subprocesses done.'
```

- `Pool`的默认大小是CPU的核数

```python
p = Pool(5)
```

### 进程间通信
- `Process`之间肯定是需要通信的
> Python的`multiprocessing模块`包装了底层的机制，提供了`Queue`、`Pipes`等多种方式来**交换数据**
- 我们以`Queue`为例，在父进程中创建两个子进程，一个往`Queue`里写数据，一个从`Queue`里读数据
```python
from multiprocessing import Process, Queue
import os, time, random

# 写数据进程执行的代码:
def write(q):
    for value in ['A', 'B', 'C']:
        print 'Put %s to queue...' % value
        q.put(value)
        time.sleep(random.random())

# 读数据进程执行的代码:
def read(q):
    while True:
        value = q.get(True)
        print 'Get %s from queue.' % value

if __name__=='__main__':
    # 父进程创建Queue，并传给各个子进程：
    q = Queue()
    pw = Process(target=write, args=(q,))
    pr = Process(target=read, args=(q,))
    # 启动子进程pw，写入:
    pw.start()
    # 启动子进程pr，读取:
    pr.start()
    # 等待pw结束:
    pw.join()
    # pr进程里是死循环，无法等待其结束，只能强行终止:
    pr.terminate()
```
- 输出
```python
Put A to queue...
Get A from queue.
Put B to queue...
Get B from queue.
Put C to queue...
Get C from queue.
```

- 父进程所有Python对象都必须通过`pickle`序列化再传到子进程去

> - 在Unix/Linux下，可以使用`fork()`调用实现多进程。
> - 要实现跨平台的多进程，可以使用`multiprocessing模块`。
> - 进程间通信是通过`Queue`、`Pipes`等实现的。