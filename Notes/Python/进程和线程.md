# 进程与线程
@(Python)[进程与线程]

## 多任务
- 就是操作系统可以同时运行多个任务
- 单核CPU是怎么执行多任务的呢？
   - 操作系统**轮流让各个任务交替执行**，任务1执行0.01秒，切换到任务2，任务2执行0.01秒，再切换到任务3，执行0.01秒……这样反复执行下去。表面上看，每个任务都是交替执行的，但是，由于CPU的执行速度实在是太快了，我们感觉就像所有任务都在同时执行一样

- 并行执行多任务只能在多核CPU上实现，由于任务数量远远多于CPU的核心数量，所以，操作系统也会自动把很多任务轮流调度到每个核心上执行

- 一个任务就是一个`进程（Process）`
- 在一个**进程内部**，要同时干多件事，就需要同时运行多个`子任务`，我们把进程内的这些“子任务”称为`线程（Thread）`
- 一个进程至少有一个线程
> 多线程的执行方式和多进程是一样的，也是由**操作系统在多个线程之间快速切换**，让每个线程都短暂地交替运行，看起来就像同时执行一样

- 同时执行多个任务怎么办？
  - 多任务的实现有3种方式
  1. 多进程模式
  2. 多线程模式
  3. 多进程+多线程模式

- 多进程和多线程的程序的复杂度要远远高于我们前面写的单进程单线程的程序,原因？
  - 同时执行多个任务通常各个任务之间并**不是没有关联的**，而是**需要相互通信和协调**
- Python既支持多进程，又支持多线程
> - **线程是最小的执行单元**，而**进程由至少一个线程组成**。  
> - 如何调度进程和线程，完全由操作系统决定，**程序自己不能决定什么时候执行，执行多长时间。**

## 多进程----multiprocessing

### 操作系统的相关知识
- Unix/Linux操作系统提供了一个`fork()`系统调用
  - `fork()`调用一次，**返回两次**，因为操作系统自动把`当前进程`（称为父进程）**复制了一份**（称为子进程），
  然后，分别在父进程和子进程内返回
  - 子进程永远返回`0`，而父进程返回子进程的`ID`
  - 一个父进程可以`fork`出很多子进程
  - 父进程要记下每个子进程的ID，而子进程只需要调用`getppid()`就可以拿到父进程的ID
- Python的`os模块`封装了常见的**系统调用**，其中就包括`fork`
- Windows**没有**`fork`调用，上面的代码在Windows上无法运行  

- 有了`fork`调用，一个进程在接到新任务时就可以复制出一个子进程来处理新任务，
> 常见的Apache服务器就是由**父进程监听端口**，每当有新的http请求时，就fork出子进程来处理新的http请求

### multiprocessing
- Python是跨平台的，自然也应该提供一个跨平台的多进程支持
- `multiprocessing模块`就是跨平台版本的多进程模块
- `multiprocessing模块`提供了一个`Process类`来代表一个**进程对象**

```Python
from multiprocessing import Process
import os

# 子进程要执行的代码
def run_proc(name):
    print 'Run child process %s (%s)...' % (name, os.getpid())

if __name__=='__main__':
    print 'Parent process %s.' % os.getpid()
    p = Process(target=run_proc, args=('test',))
    print 'Process will start.'
    p.start()
    p.join()  #join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步
    print 'Process end.'
```

### Pool
- 启动大量的子进程，可以用`进程池`的方式**批量创建子进程**
```python
from multiprocessing import Pool
import os, time, random

def long_time_task(name):
    print 'Run task %s (%s)...' % (name, os.getpid())
    start = time.time()
    time.sleep(random.random() * 3)
    end = time.time()
    print 'Task %s runs %0.2f seconds.' % (name, (end - start))

if __name__=='__main__':
    print 'Parent process %s.' % os.getpid()
    p = Pool()
    for i in range(5):
        p.apply_async(long_time_task, args=(i,))
    print 'Waiting for all subprocesses done...'
    p.close()
    p.join()
    print 'All subprocesses done.'
```

- `Pool`的默认大小是CPU的核数

```python
p = Pool(5)
```

### 进程间通信
- `Process`之间肯定是需要通信的
> Python的`multiprocessing模块`包装了底层的机制，提供了`Queue`、`Pipes`等多种方式来**交换数据**
- 我们以`Queue`为例，在父进程中创建两个子进程，一个往`Queue`里写数据，一个从`Queue`里读数据
```python
from multiprocessing import Process, Queue
import os, time, random

# 写数据进程执行的代码:
def write(q):
    for value in ['A', 'B', 'C']:
        print 'Put %s to queue...' % value
        q.put(value)
        time.sleep(random.random())

# 读数据进程执行的代码:
def read(q):
    while True:
        value = q.get(True)
        print 'Get %s from queue.' % value

if __name__=='__main__':
    # 父进程创建Queue，并传给各个子进程：
    q = Queue()
    pw = Process(target=write, args=(q,))
    pr = Process(target=read, args=(q,))
    # 启动子进程pw，写入:
    pw.start()
    # 启动子进程pr，读取:
    pr.start()
    # 等待pw结束:
    pw.join()
    # pr进程里是死循环，无法等待其结束，只能强行终止:
    pr.terminate()
```
- 输出
```python
Put A to queue...
Get A from queue.
Put B to queue...
Get B from queue.
Put C to queue...
Get C from queue.
```

- 父进程所有Python对象都必须通过`pickle`序列化再传到子进程去

> - 在Unix/Linux下，可以使用`fork()`调用实现多进程。
> - 要实现跨平台的多进程，可以使用`multiprocessing模块`。
> - 进程间通信是通过`Queue`、`Pipes`等实现的。

## 多线程

- 高级语言通常都内置**多线程的支持**
### python 的多线程模块

#### thread
- `thread`是低级模块

#### threading
- `threading`是高级模块，对`thread`进行了封装
- 绝大多数情况下，我们只需要使用`threading`这个**高级模块**。
- 启动一个线程
   - 把一个`函数`传入并创建`Thread实例`，然后调用`start()`开始执行

```python
import time, threading
# 新线程执行的代码:
def loop():
    print 'thread %s is running...' % threading.current_thread().name
    n = 0
    while n < 5:
        n = n + 1
        print 'thread %s >>> %s' % (threading.current_thread().name, n)
        time.sleep(1)
    print 'thread %s ended.' % threading.current_thread().name

print 'thread %s is running...' % threading.current_thread().name
t = threading.Thread(target=loop, name='LoopThread')
t.start()
t.join()
print 'thread %s ended.' % threading.current_thread().name
   ```

- 主线程
  > 任何进程默认就会启动一个线程,该线程就是主线程
  - 主线程实例的名字叫`MainThread`

- 子线程
  > `主线程`又可以启动新的线程-->子线程

- `current_thread()函数`
   - 永远返回当前线程的实例
   - 子线程的名字在创建时指定
   - 如果不起名字Python就自动给线程命名为`Thread-1`，`Thread-2`

### Lock
- **多进程中**，同一个变量，各自有一份拷贝存在于每个进程中，`互不影响`
- **多线程中**，所有变量都由**所有线程共享**，所以，**任何一个变量都可以被任何一个线程修改**   
   - 线程之间共享数据**最大的危险**在于多个线程同时改一个变量，把内容给改乱了,
- 如何解决？ 
  - 锁
  - 由于锁只有一个，无论多少线程，**同一时刻最多只有一个线程持有该锁，所以，不会造成修改的冲突**
- 创建一个`锁`
```python
# 创建一个锁就是通过threading.Lock()来实现
balance = 0
lock = threading.Lock()

def run_thread(n):
    for i in range(100000):
        # 先要获取锁:
        lock.acquire()
        try:
            # 放心地改吧:
            change_it(n)
        finally:
            # 改完了一定要释放锁:
            lock.release()
```  
- 多个线程同时执行`lock.acquire()`时，**只有一个线程能成功地获取锁**，然后继续执行代码，**其他线程就继续等待直到获得锁为止**
- 获得锁的线程用完后**一定要释放锁**，否则那些苦苦等待锁的线程将永远等待下去，成为`死线程`
   - 用`try...finally`来确保锁一定会被释放
- **锁的好处**就是确保了某段`关键代码`**只能由一个线程从头到尾完整地执行**
- **锁的坏处**
   - 阻止了多线程并发执行
   > 包含锁的某段代码实际上只能以单线程模式执行，**效率就大大地下降了**
   - 造成死锁
   > 由于可以**存在多个锁**，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁 ,导致多个线程全部挂起，既不能执行，也无法结束，只能靠操作系统强制终止

### 多核CPU
- 可以监控到一个死循环线程会100%占用一个CPU
- 把N核CPU的核心全部跑满，就必须启动N个死循环线程
   - Python不行,---> **多线程无法利用多核**
- `GIL`锁:Global Interpreter Lock
   > 任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核
- 在Python中，可以使用多线程，但不要指望能有效利用多核   
  - 但可以通过多进程实现多核任务

- 一个线程使用自己的`局部变量`比使用`全局变量`好，因为局部变量只有线程自己能看见，不会影响其他线程，而全局变量的修改必须加锁

> 多线程编程，模型复杂，容易发生冲突，**必须用锁加以隔离**，同时，**又要小心死锁的发生**  


## ThreadLocal
```python
import threading

# 创建全局ThreadLocal对象:
local_school = threading.local()

def process_student():
    print 'Hello, %s (in %s)' % (local_school.student, threading.current_thread().name)

def process_thread(name):
    # 绑定ThreadLocal的student:
    local_school.student = name
    process_student()

t1 = threading.Thread(target= process_thread, args=('Alice',), name='Thread-A')
t2 = threading.Thread(target= process_thread, args=('Bob',), name='Thread-B')
t1.start()
t2.start()
t1.join()
t2.join()
```

- 全局变量`local_school`就是一个`ThreadLocal对象`，每个`Thread`对它都可以读写student属性，**但互不影响**。
- 可以把`local_school`看成全局变量，但每个属性如`local_school.student`都是线程的`局部变量`，可以**任意读写而互不干扰**，**也不用管理锁的问题**，`ThreadLocal`内部会处理

> `ThreadLocal`**最常用的地方**就是为每个线程绑定一个`数据库连接`，`HTTP请求`，`用户身份信息`等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源

## 进程 vs. 线程
### Master-Worker模式
- `Master`负责分配任务
- `Worker`负责执行任务
> 多任务环境下，通常是`一个Master`，`多个Worker`

### 多进程模式
- 多进程实现Master-Worker
   - 主进程就是Master，其他进程就是Worker
- 优点
  - 优点就是稳定性高
  > 因为一个子进程崩溃了，不会影响主进程和其他子进程   
- 缺点
  - 是创建进程的`代价大`
  - 操作系统能同时运行的进程数也是有限的，*在内存和CPU的限制下，如果有几千个进程同时运行，操作系统连调度都会成问题*

### 多线程模式
- 多线程实现Master-Worker
   - 主线程就是Master，其他线程就是Worker 
- 比多进程*快一点*，但是也快不到哪去 --> Windows下，多线程的效率比多进程要高  
- 致命缺点
   - 就是任何一个线程挂掉都可能直接造成整个进程崩溃，因为**所有线程共享进程的内存**

### 线程切换
- 无论是多进程还是多线程，**只要数量一多，效率肯定上不去**
  > 切换作业是有代价的  
  > 多任务一旦多到一个限度，就会消耗掉系统所有的资源，结果效率急剧下降，所有任务都做不好

### 计算密集型 vs. IO密集型
- 计算密集型任务
   - 要进行大量的计算，消耗CPU资源
   > 如计算圆周率、对视频进行高清解码等等，全靠CPU的运算能力  
   - 计算密集型任务由于**主要消耗CPU资源**
   - 代码运行效率至关重要
   - Python这样的脚本语言运行效率很低，完全不适合计算密集型任务。
   - 对于计算密集型任务，最好用C语言编写
   - 要最高效地利用CPU，计算密集型任务同时进行的数量应当等于CPU的核心数
- IO密集型
   - 涉及到`网络`、`磁盘IO`的任务都是**IO密集型任务**   
   > 特点:CPU消耗很少，任务的大部分时间都在等待IO操作完成 *(因为IO的速度远远低于CPU和内存的速度）*
   - 常见的**大部分任务都是IO密集型任务**，*比如Web应用*
   - IO密集型任务执行期间，**99%的时间都花在IO上**，花在CPU上的时间很少
   - 对于IO密集型任务，最合适的语言就是开发效率最高（代码量最少）的语言，脚本语言是首选，C语言最差

## 异步IO
- `CPU`和`IO`之间**巨大的速度差异**,一个任务在执行的过程中大部分时间都在**等待IO操作**
- 支持**异步IO**
   - 用**单进程单线程**模型来执行**多任务** ---> `事件驱动模型`
   - 异步IO编程模型来实现多任务是一个主要的趋势
- 协程
  - Python语言，单进程的异步编程模型   

## 分布式进程
- 在`Thread`和`Process`中，应当**优选**`Process`，因为`Process`更稳定，而且，
- `Process`可以分布到多台机器上，而T`hread`最多只能分布到同一台机器的多个CPU上

> Python的`multiprocessing模块`不但支持多进程，其中`managers子模块`还支持把多进程分布到多台机器上。一个`服务进程`可以作为**调度者**，将任务分布到其他多个进程中，依靠网络通信。由于`managers模块`封装很好，不必了解网络通信的细节，就可以很容易地编写分布式多进程程序。
  - **服务进程:** 服务进程负责启动`Queue`，把`Queue`注册到网络上，然后往`Queue`里面写入任务
  - **任务进程:**在另一台机器上启动任务进程

